<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="../css/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="../css/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="../css/print.css" media="print" />

    <title>Trevor's Robotics and Computer Vision Website.</title>
  </head>

  <body>
    <header>
      <div class="container">
        <h1>Trevor's Robotics Website</h1>
        <h2>A website to showcase my Robotics, Computer Vision and general technical projects.</h2>

        <section id="downloads">
          <a href="../docs/Trevor_Sherrard_Resume.pdf" class="btn btn-resume"><span class="icon"></span>Resume</a>
          <a href="https://github.com/sherrardTr4129" class="btn btn-github"><span class="icon"></span>GitHub</a>
          <a href="robotics_experience.html" class=btn btn-github>Robotics Projects</a>
          <a href="ComputerVision.html" class=btn btn-github>CV Projects</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
  
<h3><a name="welcome-to-github-pages" class="anchor" href="Kudos.html#welcome-to-github-pages"><span class="octicon octicon-link"></span></a>Low Cost Pandemic Telenursing Robot</h3>

<p>This page outlines the work I have completed thus far on a low-cost telenursing robot platform based on the LoCoBot research robotics platform. This platform was designed for deployment in African university hospitals for the purpose of increasing the overall effectiveness of nursing staff in pandemic conditions. The LoCoBot platform uses a Kubuki mobile base, a 5-DOF manipulator arm, and an Intel RealSense camera on a pan-tilt base for world interfacing operations. The customization efforts performed on this robot platform include the addition of a ydlidar G2 sensor on top of a 3D-printed mechanical platform to enhance localization abilities of the robot. A touch screen was also mounted on the back of the robot's equipment tower to serve as a human-robot interface. The most up to date version of the developed software can be found <a href="https://github.com/sherrardTr4129/LoCoBot-Telenursing-Platform">in this GitHub repository</a>. The robot in its current state can be seen in the figure below.</p>

<img src="../images/LoCoBot_Telenursing_platform.jpg" alt="LoCoBot" height= "1000" width= "550">

<br/><br/>
<h3><a name="welcome-to-github-pages" class="anchor" href="Kudos.html#welcome-to-github-pages"><span class="octicon octicon-link"></span></a>Cross-Domain Control Web Interface</h3>

<p>A custom web interface was developed to operate the robot remotely. This interface allowed for direct control of the robot's various axes of motion through javascript joysticks and push buttons within the interface itself. User input was then fed to a backend python flask application that made HTTP requests to another flask application running on the robot. This robot-side flask application was able to format and republish user input data to the robot in a way that was consumed by the different robot control API's made available through the pyRobot ROS software stack. Visual feedback from the robot's pan-tilt Intel RealSense camera was streamed back to the user interface from the robot to aid in teleoperation. The overall system architecture can be seen in the figure below.</p>

<img src="../images/detailedArch.png" alt="Web Interace Arch" height= "800" width= "575">

<p>Several interface usability experients were performed using a robot in a gazebo simulation. Once we were satisfied with the performance of the robot, the same software stack was set up using the physical LoCoBot platform. It was found that the system's overall responsiveness was good, and the robot was indeed controllable via the web interface from a phone and a standard desktop computer. A video showing the constructed teleoperation paradigm can be seen in the video below.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/m7gPYqWC6_M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br /><br />
<h3><a name="welcome-to-github-pages" class="anchor" href="Kudos.html#welcome-to-github-pages"><span class="octicon octicon-link"></span></a>New Sensor Integration</h3>

<p>From here, the LiDAR sensor was verified to work using the provided driver from Yglidar. The robot was teleoperated and the data obtained from the lidar was streamed through the cross-web data bridge. The generated point cloud was the visualized within an RVIZ instance. This demonstration can be seen in the video below.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Wq2Khx38Ky0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br><br>
<h3><a name="welcome-to-github-pages" class="anchor" href="Kudos.html#welcome-to-github-pages"><span class="octicon octicon-link"></span></a>Automatic Viewpoint Selection For Manipulation</h3>
<p>The first shared autonomy developed for this platform is automatic viewpoint selection for manipulator control. In this paradigm, a vision target is attached to the end of the robotic arm end-effector. This vision target is isolated within frames obtained by the pan-tilt camera and the center point of the target is obtained. A buffer zone is defined within the image, and if the target strays outside of the buffer zone, the camera moves accordingly to bring it back into view. If the target stays within the buffer, no motion commands are given to the pan-tilt camera. This paradigm allows the user to focus on telemanipulation tasks without needing to focus on adjusting the pan or tilt of the camera itself. Please see the demo video below for more information.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/_EvY3IyhWfU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


      </section>
    </div>
  </body>
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-65376015-1', 'auto');
  ga('send', 'pageview');

  </script>
</html>
